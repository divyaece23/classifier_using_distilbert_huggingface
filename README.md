# Classifier Using DistilBERT (Hugging Face)

This repository contains a text classification pipeline using the **DistilBERT** transformer model from the Hugging Face Transformers library.

## ðŸ§  Model Overview

- **Base Model:** [DistilBERT](https://huggingface.co/distilbert-base-uncased)
- **Task:** Text classification (Binary or Multi-class)
- **Library:** Hugging Face Transformers + Datasets

DistilBERT is a smaller, faster, and lighter version of BERT.


